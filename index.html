<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Faux-Hate - ICON 2024 shared task on decoding fake narratives in spreading hateful stories.">
    <title>Faux-Hate: ICON 2024</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Welcome to the <a href="https://www.au-kbc.org/icon2024/" target="_blank" style="text-decoration: underline; color: white;">ICON 2024</a> shared task on <em>Decoding Fake Narratives in Spreading Hateful Stories (Faux-Hate)</em></h1>
    </header>

    <section id="introduction">
        <h2>Introduction</h2>
        <p>Social media has revolutionized the way we communicate, but it has also opened the door for the rapid spread of harmful content, including hate speech. Hate speech on social platforms not only affects individuals and communities but can also escalate into violence and societal harm. In recent years, there has been a growing concern about the intersection of <strong>hate speech</strong> and <strong>fake narratives</strong>, which has prompted the need for specialized methods to detect and curb their spread.</p>
        <h3>What is Faux-Hate?</h3>
        <p>Briefly, Faux-Hate is the generation of <strong>hate speech</strong> driven by <strong>fake narratives</strong>. This task focuses on identifying comments that blend fake information with hateful language to mislead and provoke individuals, exacerbating the impact of hate speech. The goal of this shared task is to explore how fake narratives can contribute to the propagation of hate and to develop models that can detect such instances within code-mixed Hindi-English social media text.</p>
    </section>

    <section id="task-overview">
        <h2>Task Overview</h2>
        <p>The <strong>Faux-Hate</strong> shared task is designed to challenge participants to tackle both <strong>fake</strong> and <strong>hate</strong> detection in social media comments, with additional emphasis on identifying the <strong>target</strong> and <strong>severity</strong> of hateful speech.</p>

        <h3>Key Concepts:</h3>
        <ul>
            <li><strong>Fake</strong>: Misinformation deliberately spread with the intention to mislead.</li>
            <li><strong>Hate</strong>: Speech intended to marginalize individuals or groups based on attributes like religion, ethnicity, or political beliefs.</li>
            <li><strong>Target</strong>: The intended subject of the hate speech, classified as either an individual, organization, or religion.</li>
            <li><strong>Severity</strong>: The intensity of the hate speech, ranging from low (disagreement) to high (advocating violence).</li>
        </ul>

        <h3>Sub-tasks:</h3>
        <ol>
            <li>
                <strong>Task A - Binary Faux-Hate Detection</strong>
                <p>Participants will receive a dataset containing text samples, each labeled with:</p>
                <ul>
                    <li><strong>Fake:</strong> Binary label indicating if the content is fake (1) or real (0).</li>
                    <li><strong>Hate:</strong> Binary label indicating if the content is hate speech (1) or not (0).</li>
                </ul>
                <p>The objective of this sub-task is to develop a single <b>multi-tasking model</b> that outputs both the fake and hate labels for each text sample.</p>
            </li>
            <li>
                <strong>Task B - Target and Severity Prediction</strong>
                <p>Participants will receive a dataset containing text samples, each labeled with:</p>
                <ul>
                    <li><strong>Target:</strong> Categorical label indicating the target of the content (Individual (I), Organization (O), and Religion (R)).</li>
                    <li><strong>Severity:</strong> Categorical label indicating the severity of the content (Low (L), Medium (M), and High (H)).</li>
                </ul>
                <p>The objective of this sub-task is to develop a single model that generates both the target and severity labels for a given text sample.</p>
            </li>
        </ol>
    </section>

    <section id="dataset">
        <h2>Dataset</h2>
        <p>The provided dataset is divided into three sections, each set will be available for download on the respective release dates.</p>
        <table>
            <thead>
                <tr>
                    <th>Dataset</th>
                    <th>Date of Release</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Train</td>
                    <td>(release date)</td>
                </tr>
                <tr>
                    <td>Validation</td>
                    <td>(release date)</td>
                </tr>
                <tr>
                    <td>Test</td>
                    <td>(release date)</td>
                </tr>
            </tbody>
        </table>
    </section>

    <section id="evaluation-metrics">
        <h2>Evaluation Metrics</h2>
        <p>We will use the Macro F1 Score as the primary evaluation metric for both Task A and Task B.</p>
    </section>

    <section id="registration">
        <h2>Registration</h2>
        <p>To participate, please fill out the registration form. <a href="#">Click here to register</a> (link will be provided soon).</p>
        <p>Upon successful registration, participants will receive the dataset via email. Please ensure your email address is valid and accessible during the competition.</p>
    </section>


    <section id="timeline">
        <h2>Timeline</h2>
        <ul>
            <li>20th Oct - Open track website and training data release</li>
            <li>10th Nov - Test data release</li>
            <li>15th Nov - Run submission deadline</li>
            <li>17th Nov - Results announced</li>
            <li>25th Nov - Working notes submission deadline</li>
            <li>10th Dec - Acceptance notification</li>
            <li>15th Dec - Camera-ready submission deadline</li>
        </ul>
    </section>

    <section id="organizers" style="color: #4B0082;">
        <h2>Organizers</h2>
        <ul>
            <li><a href="https://www.linkedin.com/in/shankar-biradar-bb613826/" target="_blank">Shankar Biradar</a> (KLE Technological University)</li>
            <li><a href="https://www.linkedin.com/in/sai-kartheek-reddy-kasu/" target="_blank">Kasu Sai Kartheek Reddy</a> (Indian Institute of Information Technology Dharwad)</li>
            <li><a href="https://scholar.google.com/citations?user=QItKUEMAAAAJ&hl=en" target="_blank">Sunil Saumya</a> (Indian Institute of Information Technology Dharwad)</li>
            <li><a href="http://faculty.iiitd.ac.in/~shad.akhtar/" target="_blank">Md. Shad Akhtar</a> (Indraprastha Institute of Information Technology Delhi)</li>
        </ul>
    </section>

<section id="citation" style="margin-top: 20px;">
    <h2>Citation Requirement for Participants</h2>
    <p>All participants are required to cite the following article in their working notes:</p>
    <blockquote>
        <pre>
@article{biradar2024faux,
  title={Faux Hate: Unravelling the Web of Fake Narratives in Spreading Hateful Stories: 
         A Multi-Label and Multi-Class Dataset in Cross-Lingual Hindi-English Code-Mixed Text},
  author={Biradar, Shankar and Saumya, Sunil and Chauhan, Arun},
  journal={Language Resources and Evaluation},
  pages={1--32},
  year={2024},
  publisher={Springer}
}
        </pre>
    </blockquote>
    <p>This citation is essential for acknowledging the foundational work that contributes to the shared task and ensuring proper attribution in your research.</p>
</section>
    
</body>
</html>
